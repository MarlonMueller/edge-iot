#pragma once

#include <stdint.h>

#include "dl_layer_model.hpp"
#include "dl_layer_relu.hpp"
#include "dl_layer_conv2d.hpp"
#include "dl_layer_softmax.hpp"
#include "dl_layer_flatten.hpp"
#include "dl_layer_max_pool2d.hpp"
#include "dl_layer_fullyconnected.hpp"

#include "{{ model_name }}_coefficient.hpp"

using namespace dl;
using namespace layer;
using namespace {{ model_name }}_coefficient;

class {{ model_name | upper }} : public Model<{{ quantization_bit }}_t>
{
private:

    {% for l in layers -%}
    {% if not loop.last -%}
    {%if l['layer'] == "conv2d" -%}
    Conv2D<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "flatten" -%}
    Flatten<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "maxpool2d" -%}
    MaxPool2D<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "softmax" -%}
    Softmax<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "fc" -%}
    FullyConnected<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "relu" -%}
    Relu<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% endif -%}
    {%- endif -%}
    {% endfor %}

public:

    {% for l in layers -%}
    {% if loop.last -%}
    {%if l['layer'] == "conv2d" -%}
    Conv2D<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "flatten" -%}
    Flatten<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "maxpool2d" -%}
    MaxPool2D<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "softmax" -%}
    Softmax<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "fc" -%}
    FullyConnected<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% elif l['layer'] == "relu" -%}
    Relu<{{ quantization_bit }}_t> {{ l['layer_name'] }};
    {% endif -%}
    {%- endif -%}
    {%- endfor %}

    {{ model_name | upper }}() :
    {%- for l in layers %}

        {%- if loop.last %}
        {% set delimiter = '{}' %}
        {%- else %}
        {% set delimiter = ',' %}
        {%- endif -%}

        {%if l['layer'] == "conv2d" -%}
        {%if l['activation'] -%}
        {{ l['layer_name'] }}(Conv2D<{{ quantization_bit }}_t>({{ l['output_exponent'] }}, get__{{ l['layer_name'] }}_conv_filter(), get__{{ l['layer_name'] }}_conv_bias(), get__{{ l['layer_name'] }}_conv_activation(), {{ l['padding_type'] }}, {{ l['padding'] }}, {{ l['stride_y'] }}, {{ l['stride_x'] }}, "{{ l['layer_name'] }}")){{ delimiter }}
        {%- else %}
        {{ l['layer_name'] }}(Conv2D<{{ quantization_bit }}_t>({{ l['output_exponent'] }}, get__{{ l['layer_name'] }}_conv_filter(), get__{{ l['layer_name'] }}_conv_bias(), NULL, {{ l['padding_type'] }}, {{ l['padding'] }}, {{ l['stride_y'] }}, {{ l['stride_x'] }}, "{{ l['layer_name'] }}")){{ delimiter }}
        {% endif -%}
        {% elif l['layer'] == "flatten" -%}
        {{ l['layer_name'] }}(Flatten<{{ quantization_bit }}_t>("{{ l['layer_name'] }}", {{ l['inplace'] }})){{ delimiter }}
        {% elif l['layer'] == "maxpool2d" -%}
        {{ l['layer_name'] }}(MaxPool2D<{{ quantization_bit }}_t>({{ l['filter_shape'] }}, {{ l['padding_type'] }}, {{ l['padding'] }}, {{ l['stride_y'] }}, {{ l['stride_x'] }}, "{{ l['layer_name'] }}")){{ delimiter }}
        {% elif l['layer'] == "softmax" -%}
        {{ l['layer_name'] }}(Softmax<{{ quantization_bit }}_t>({{ l['output_exponent'] }}, "{{ l['layer_name'] }}")){{ delimiter }}
        {% elif l['layer'] == "fc" -%}
        {%if l['activation'] -%}
        {{ l['layer_name'] }}(FullyConnected<{{ quantization_bit }}_t>({{ l['output_exponent'] }}, get__{{ l['layer_name'] }}_gemm_filter(), get__{{ l['layer_name'] }}_gemm_bias(), get__{{ l['layer_name'] }}_gemm_activation(), {{ l['flatten'] }}, "{{ l['layer_name'] }}")){{ delimiter }}
        {%- else %}
        {{ l['layer_name'] }}(FullyConnected<{{ quantization_bit }}_t>({{ l['output_exponent'] }}, get__{{ l['layer_name'] }}_gemm_filter(), get__{{ l['layer_name'] }}_gemm_bias(), NULL, {{ l['flatten'] }}, "{{ l['layer_name'] }}")){{ delimiter }}
        {% endif -%}
        {% elif l['layer'] == "relu" -%}
        {{ l['layer_name'] }}(Relu<{{ quantization_bit }}_t>("{{ l['layer_name'] }}", {{ l['inplace'] }})){{ delimiter }}
        {% endif -%}

    {% endfor %}

    void build(Tensor<{{ quantization_bit }}_t>& input) {
        
        {% for l in layers -%}
        {% if loop.first %}
        this->{{ l['layer_name'] }}.build(input);
        {% else %}
        this->{{ l['layer_name'] }}.build(this->{{ l['previous_layer_name'] }}.get_output(), true);
        {% endif %}
        {%-  endfor %}
    }

    void call(Tensor<{{ quantization_bit }}_t>& input) {
        
        {% for l in layers -%}
        {% if loop.first %}
        this->{{ l['layer_name'] }}.call(input);
        input.free_element();
        {% else %}
        this->{{ l['layer_name'] }}.call(this->{{ l['previous_layer_name'] }}.get_output());
        this->{{ l['previous_layer_name'] }}.get_output().free_element();
        {% endif %}
        {%- endfor %}
    }
};